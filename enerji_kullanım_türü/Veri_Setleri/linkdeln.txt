BaÅŸlÄ±k: NASA UydularÄ±ndan Stratejik Karar MekanizmalarÄ±na: Enerji Ä°stihbaratÄ±nÄ±n GeleceÄŸi ğŸŒğŸ’

Ramazan boyunca her hafta yayÄ±nladÄ±ÄŸÄ±m "Data Engineering & Science" serisinin 2. haftasÄ±ndayÄ±z. Bu hafta konumuz; ham verinin "Big Data" teknolojileriyle iÅŸlenip stratejik bir gÃ¼ce dÃ¶nÃ¼ÅŸtÃ¼ÄŸÃ¼ Global Energy & Climate Intelligence Hub (GECI).

Bu projede sadece bir dashboard yapmadÄ±m; verinin devasa boru hatlarÄ±nda nasÄ±l aktÄ±ÄŸÄ±nÄ±, temizlendiÄŸini ve depolandÄ±ÄŸÄ±nÄ± yÃ¶neten bir Modern Data Stack inÅŸa ettim.

Ä°ÅŸte bu haftaki "mutfak" yolculuÄŸumdan teknik notlar:

ğŸ”¥ Big Data'nÄ±n Kalbi: Apache Spark:
Milyonlarca satÄ±rlÄ±k enerji ve emisyon verisini tek bir bilgisayarda iÅŸlemek imkansÄ±za yakÄ±ndÄ±r. Bu yÃ¼zden projenin merkezine PySpark'Ä± koydum. DaÄŸÄ±tÄ±k veri iÅŸleme motoru sayesinde, farklÄ± kaynaklardan gelen heterojen verileri saniyeler iÃ§inde normalize edip, karmaÅŸÄ±k "Join" operasyonlarÄ±nÄ± bellek iÃ§inde (in-memory) tamamladÄ±m.

ğŸ“¦ S3 StandartlarÄ±nda Data Lake: MinIO:
Veriyi doÄŸrudan veritabanÄ±na atmak yerine, Ã¶nce "Raw Data" olarak MinIO Ã¼zerinde depoladÄ±m. Docker konteynerlerinde koÅŸan bu S3 uyumlu nesne depolama katmanÄ±, projenin Ã¶lÃ§eklenebilirliÄŸinin (scalability) temel taÅŸÄ± oldu.

ğŸ›ï¸ Veri AmbarÄ± (Data Warehouse): PostgreSQL 15:
Spark ile rafine ettiÄŸim verileri, analiz iÃ§in optimize edilmiÅŸ bir ÅŸemada PostgreSQLâ€™e aktardÄ±m. Burada "Fact Table" mimarisini kurgulayarak, Streamlit arayÃ¼zÃ¼nÃ¼n binlerce satÄ±r arasÄ±ndan milisaniyeler iÃ§inde sonuÃ§ getirmesini saÄŸladÄ±m.

ğŸ›°ï¸ NASA API & Hibrit Veri HattÄ±:
Sadece statik dosyalarla yetinmedim. NASA POWER API Ã¼zerinden gelen 25 yÄ±llÄ±k uydu verisiyle, sahadan gelen canlÄ± sensÃ¶r verilerini Spark Ã¼zerinde birleÅŸtiren bir "Hybrid Engine" kurguladÄ±m.

ğŸŒ¡ï¸ Fizik TabanlÄ± ML:
Veri bilimini fizik kurallarÄ±yla gÃ¼Ã§lendirdim. "Thermal Derating" etkisini (sÄ±caklÄ±k arttÄ±kÃ§a panel veriminin dÃ¼ÅŸmesi) modellerime bir "domain kÄ±sÄ±tÄ±" olarak ekledim.

HaftanÄ±n Notu:
Veri mÃ¼hendisliÄŸi, sadece boru dÃ¶ÅŸemek deÄŸildir; o borularÄ±n iÃ§inden geÃ§en sÄ±vÄ±nÄ±n kalitesini ve gÃ¼venliÄŸini garanti etmektir. Bu yÃ¼zden projeye Unittest katmanÄ±nÄ± ekleyerek veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ her adÄ±mda doÄŸruladÄ±m.

Serinin Ã¶nÃ¼mÃ¼zdeki haftalarÄ±nda bu veriyi "aksiyona" nasÄ±l dÃ¶keceÄŸimizi konuÅŸacaÄŸÄ±z. TÃ¼m mimari, Docker yapÄ±landÄ±rmasÄ± ve Spark kodlarÄ± GitHub'da sizi bekliyor!.

ğŸ”— [GitHub Linkiniz]

#BigData #DataEngineering #ApacheSpark #MinIO #PostgreSQL #NASA #MachineLearning #Python #PySpark #ModernDataStack #RamazanProjects #EnergyTransition